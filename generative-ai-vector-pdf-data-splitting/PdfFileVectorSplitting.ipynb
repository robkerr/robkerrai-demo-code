{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Libraries and Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries into kernel (if not already installed)\n",
    "# %pip install pinecone-client\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Python data handling environment imports \n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "# Pinecone is a cloud-based Vector Database we'll use \n",
    "# to store embeddings\n",
    "import pinecone\n",
    "\n",
    "# OpenAI is used for the embedding LLM and GenAI model \n",
    "# used to generate responses\n",
    "import openai\n",
    "\n",
    "# Langchain is middleware that ties together the components \n",
    "# of the embedding and retrieval pipelines \n",
    "\n",
    "# The embedding chain creates searchable vectors of our data\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "# from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# A link in the chain to operate a chat session\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# We'll maintain some memory of the chat so follow-up questions\n",
    "# will be context-sensitive\n",
    "from langchain.chains.conversation.memory \\\n",
    "import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Environment Variables\n",
    "\n",
    "When using VSCode, install the dotenv extension and create an .env file with these contents:\n",
    "\n",
    "OPENAI_KEY=YOUR_OPENAI_API_KEY\n",
    "\n",
    "PINECONE_KEY=YOUR_PINECONE_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "OPENAI_KEY=os.getenv(\"OPENAI_KEY\")\n",
    "openai.api_key = OPENAI_KEY\n",
    "EMBEDDING_MODEL=\"text-embedding-ada-002\"\n",
    "GENAI_MODEL='gpt-3.5-turbo'\n",
    "\n",
    "PINECONE_KEY=os.getenv(\"PINECONE_KEY\")\n",
    "PINECONE_ENV=\"gcp-starter\"\n",
    "PINECONE_INDEX_NAME=\"default\" # this will be created below\n",
    "\n",
    "print(OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Pinecone Vector Database if does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index...\n",
      "IndexDescription(name='default', metric='dotproduct', replicas=1, dimension=1536.0, shards=1, pods=1, pod_type='starter', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(api_key = PINECONE_KEY, environment = PINECONE_ENV)\n",
    "index_list = pinecone.list_indexes()\n",
    "if len(index_list) == 0:\n",
    "    print(\"Creating index...\")\n",
    "    pinecone.create_index(PINECONE_INDEX_NAME, dimension=1536, metric='dotproduct')\n",
    "    \n",
    "print(pinecone.describe_index(PINECONE_INDEX_NAME))\n",
    "index = pinecone.Index(PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Embedding Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This references the text-embedding-ada-002 OpenAI model we'll use to create embeddings \n",
    "# Both for indexing ground knowledge content, and later when searching ground knowledge\n",
    "# For RAG documents to include in LLM Prompts\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model = EMBEDDING_MODEL,\n",
    "    openai_api_key= OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Function to Split PDF File into Vectors & UPSERT vectors to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file):   \n",
    "    print(f\"Splitting and vectorizing file: {file}\")\n",
    "    \n",
    "    # load document from file disk\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # split documents into text and embeddings\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # Vectorize chunks of file, submitting 20 chunks at a time to OpenAI\n",
    "    batch_size = 20 \n",
    "    for i in tqdm(range(0, len(docs), batch_size)):\n",
    "        # OpenAPI has rate limits, and we use batches to slow the pace of embedding requests\n",
    "        i_end = min(i+batch_size, len(docs))\n",
    "        batch = docs[i:i_end]\n",
    "        \n",
    "        # When querying the Vector DB for nearest vectors, the metadata \n",
    "        # is what is returned and added to the LLM Prompt (the \"Grounding Knowledge\")\n",
    "        ids = []\n",
    "        context_array = []\n",
    "        meta_data = []\n",
    "        for i, row in enumerate(batch):\n",
    "            print(f\"appending {i}\")\n",
    "            # Create a UUID\n",
    "            ids.append(str(uuid.uuid4()))\n",
    "            context_array.append(row.page_content)\n",
    "            meta_data.append({\n",
    "                'source': row.metadata[\"source\"],\n",
    "                'page': row.metadata[\"page\"] + 1,\n",
    "                'context': row.page_content\n",
    "            })            \n",
    "        \n",
    "        # print(ids)\n",
    "        # print(meta_data)\n",
    "        \n",
    "        \n",
    "        # Get a list of documents to submit to OpenAI for embedding  \n",
    "        emb_vectors = embed.embed_documents(context_array) \n",
    "        \n",
    "        # Add embeddings, associated metadata, and the keys to the vector DB\n",
    "        to_upsert = zip(id, emb_vectors, meta_data)    \n",
    "        index.upsert(vectors=to_upsert)\n",
    "\n",
    "    \n",
    "        # Pause after each batch to avoid rate limits\n",
    "        time.sleep(2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_db('files/2019-21-51_Emergency.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a simple query to the Vector Index to ensure we it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='1  FAA \\nAviation Safety  EMERGENCY \\nAIRWORTHINESS DIRECTIVE  \\nwww.faa.gov/aircraft/safety/alerts/  \\nDATE: October  23, 2019  \\nAD #: 2019 -21-51 \\nEmergency Airworthiness Directive (AD) 2019- 21-51 is sent to owners and operators of \\nGeneral Electric Company  (GE)  Model GE90 -115B  model turbofan e ngines  with certain  engine \\nserial  numbers . \\nBackground  \\nThis emergency AD was prompted by an  event  that occurred  on October 20, 2019,  in which  a \\nBoeing Model 777-300ER  airplane powered by GE GE90 -115B  model turbofan engines experienced \\nan uncontained high-pressure turbine (HPT) failure  that resulted in an aborted takeoff . Debris \\nimpacted the aircraft fuselage and the other engine. Uncontained HPT failure , if not addressed, could \\nresult in release of high -energy debris, damage  to the engine, damage to the airplane, and possible \\nloss of the airplane . \\nRelevant Service Information  \\nThe FAA reviewed GE Alert Service Bulletin GE90 -100 S/B 72 -A0826, dated October  23,', metadata={'page': 1.0, 'source': 'files/2019-21-51_Emergency.pdf'}),\n",
       " Document(page_content='2 This AD is issued in accordance with authority delegated by the Executive Director, Aircraft \\nCertification Service, as authorized by FAA Order 8000.51C. In accordance with that order, issuance \\nof ADs is normally a function of the Compliance and Airworthiness Division, but during this \\ntransition period, the Executive Director has del egated the authority to issue ADs applicable to \\nengines, propellers, and associated appliances to the Manager, Engine and Propeller Standards \\nBranch, Policy and Innovation Division.  \\nPresentation of the Actual AD  \\nThe FAA is  issuing this AD under 49 U.S.C.  Section  44701 according to the authority \\ndelegated to me by the Administrator.  \\n2019- 21-51 General  Electric Company:  Product  Identifier  2019- NE-32-AD. \\n(a) Effective Date \\nThis Emergency AD is effective upon receipt.  \\n(b) Affected ADs  \\nNone.  \\n(c) Applicability  \\nThis AD applies to  all General Electric Company (GE)  GE90 -115B  model turbofan engines', metadata={'page': 2.0, 'source': 'files/2019-21-51_Emergency.pdf'}),\n",
       " Document(page_content='Authority for this Rulemaking  \\nTitle 49 of the United States Code specifies the FAA’s authority to issue rules on aviation \\nsafety. Subtitle  I, Section  106, describes t he authority of the FAA Administrator. Subtitle  VII, \\nAviation Programs, describes in more detail the scope of the Agency’s authority.  \\nThe FAA is  issuing this rulemaking under the authority described in Subtitle  VII, Part  A, \\nSubpart  III, Section  44701, “Gen eral requirements.” Under that section, Congress charges the FAA \\nwith promoting safe flight of civil aircraft in air commerce by prescribing regulations for practices, \\nmethods, and procedures the Administrator finds necessary for safety in air commerce. Th is \\nregulation is within the scope of that authority because it addresses an unsafe condition that is likely \\nto exist or develop on products identified in this rulemaking action.', metadata={'page': 1.0, 'source': 'files/2019-21-51_Emergency.pdf'})]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = Pinecone(index, embed, \"context\")\n",
    "query = \"What model aircraft is affected by directive 2019-21-51?\" #ask some question that's answerable with the content added to the Vector DB\n",
    "vectorstore.similarity_search(query, k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a GPT 3.5 Turbo Chatbot with a 5 response memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reference to the OpenAI LLM\n",
    "llm = ChatOpenAI(openai_api_key = OPENAI_KEY,\n",
    "                model_name = GENAI_MODEL,\n",
    "                temperature = 0.0)\n",
    "\n",
    "# Ensure the chat session includes memory of 5 previous messages\n",
    "conv_mem = ConversationBufferWindowMemory(\n",
    "    memory_key = 'history',\n",
    "    k = 5,\n",
    "    return_messages =True)\n",
    "\n",
    "# Create the chain to manage the chat session\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now have a conversation about the documents that were added to the grounding data vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Directive 2019-21-51 affects the Boeing Model 777-300ER airplane powered by GE GE90-115B model turbofan engines.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"What model aircraft is affected by directive 2019-21-51?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Uncontained high-pressure turbine (HPT) failure\\n- Release of high-energy debris\\n- Damage to the engine\\n- Damage to the airplane\\n- Possible loss of the airplane'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"what are the unsafe conditions? Format as a bulleted list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(\"Does dell make surfboards?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(\"Do they make laptops?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.run(\"Who founded Dell computer?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
